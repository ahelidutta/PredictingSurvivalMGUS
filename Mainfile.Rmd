---
title: "Extreme gradient boosted classification and regression trees to predict outcomes in patients with monoclonal gammapathies of undermind significance"
author: "Aheli Dutta, Jordan Gauthier"
Date: "February 2020"
output: rmarkdown::github_document
---

```{r setup}
library(dplyr)
library("survival")
library("survminer")
library("gtsummary")
library(knitr)
library(tidyr)
library(xgboost)
library(tidymodels)
library(mice)
#library(haven)

```


#data exploration
```{r data exploration}
df_mgus <- survival::mgus2 %>% 
  dplyr::select(age,dxyr,hgb,creat,mspike,pstat)

sapply(df_mgus,sd)


#distribution of data
par(mfrow = c(2,3))
for( i in 1:5){
  hist(df_mgus[,i], main = colnames(df_mgus)[i],xlab = colnames(df_mgus)[i], col = 'light blue')
}

#box plots
par(mfrow = c(2,3))
boxplot(mspike~pstat, ylab = "Monoclonal Serum Splike", xLab = "Progression to PCM", col = "light green", data = df_mgus)
boxplot(hgb~pstat, ylab = "Hemoglobin", xLab = "Progression to PCM", col = "light green", data = df_mgus)
boxplot(creat~pstat, ylab = "Creatinine", xLab = "Progression to PCM", col = "light green", data = df_mgus)
boxplot(age~pstat, ylab = "Age", xLab = "Progression to PCM", col = "light green", data = df_mgus)
boxplot(dxyr~pstat, ylab = "Year Diagnosed", xLab = "Progression to PCM", col = "light green", data = df_mgus)

```


#XGBoost Model

```{r}
set.seed(123)
mgus_df <- complete(mice(mgus2, m=1, maxit = 50, method = 'pmm', seed = 500),1)
#mgusNew_df <- read.csv("mgus_custom_data.csv")

mgus_split <- mgus_df %>% 
  dplyr::select(-futime,-death,-id,-ptime) %>% 
  initial_split(., strata = pstat)
mgus_train <- read.csv("mgus_custom_data_train.csv") %>% 
  dplyr::select(-X,-Unnamed..0)
mgus_test <- testing(mgus_split)
```

```{r}
xgb_spec <- boost_tree(
  trees = 1000,
  tree_depth = tune(), min_n = tune(), loss_reduction = tune(),
  sample_size = tune(), mtry = tune(), learn_rate = tune()
) %>%
  set_engine("xgboost", objective = 'binary:logistic') %>%
  set_mode('regression')

xgb_spec
```

```{r}
xgb_grid <- grid_latin_hypercube(
  tree_depth(),
  min_n(),
  loss_reduction(),
  sample_size = sample_prop(),
  finalize(mtry(), mgus_train),
  learn_rate(),
  size = 30
)

xgb_grid
```

```{r}
xgb_wf <- workflow() %>%
  add_formula(pstat ~ .) %>%
  add_model(xgb_spec)
```

```{r}
set.seed(123)
mgus_folds <- vfold_cv(mgus_train, strata = pstat)
mgus_folds
```

```{r}
doParallel::registerDoParallel()

set.seed(234)
xgb_res <- tune_grid(
  xgb_wf,
  resamples = mgus_folds,
  grid = xgb_grid, 
  control = control_grid(save_pred = TRUE)
)
```

```{r}
xgb_res %>%
  collect_metrics() %>%
  dplyr::filter(.metric == "rmse") %>%
  dplyr::select(mean, mtry:sample_size) %>%
  pivot_longer(mtry:sample_size,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "RMSE")

show_best(xgb_res, "rmse")

best_rmse <- select_best(xgb_res, "rmse")
best_rmse

final_xgb <- finalize_workflow(
  xgb_wf,
  best_rmse
)

final_xgb
```

```{r}
library(vip)
final_xgb %>%
  fit(data = mgus_train) %>%
  pull_workflow_fit() %>%
  vip(geom = "point")

final_res <- last_fit(final_xgb, mgus_split)

collect_metrics(final_res)
final_res %>%
  collect_predictions() %>%
  mutate(pstat = as.factor(pstat))      %>%
  roc_curve(pstat, .pred) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(size = 1.5, color = "midnightblue") +
  geom_abline(
    lty = 2, alpha = 0.5,
    color = "gray50",
    size = 1.2
  )


#Visuals
library(runway)
final_res %>%
  collect_predictions() %>% 
  threshperf_plot(.,
                outcome = 'pstat',
                prediction = '.pred')

final_res %>%
  collect_predictions() %>% 
  cal_plot(.,
         outcome = 'pstat', 
         prediction = '.pred',
         show_loess = TRUE)

final_res %>%
  collect_predictions() %>% 
  roc_plot(., 
         outcome = 'pstat', 
         prediction = '.pred',
         ci = TRUE, 
         plot_title = 'Single ROC curve w/CI ribbon')
```


#regression model

```{r}
set.seed(123)
mgus_df_lg <- complete(mice(mgus2, m=1, maxit = 50, method = 'pmm', seed = 500),1)
mgus_split_lg <- mgus_df_lg %>% 
  dplyr::select(-futime,-death,-id,-ptime) %>% 
  initial_split(., strata = pstat)
mgus_train_lg <- read.csv("mgus_custom_data_glm.csv") %>% 
  dplyr::select(-X,-Unnamed..0)
mgus_test_lg <- testing(mgus_split)

lg.train <- mgus_train_lg
lg.test <- mgus_test_lg


```

```{r}
library(pROC)
library(runway)
model <- glm(pstat~ sex+ age + hgb+ mspike + dxyr + creat, data = lg.train, family = "binomial",control = list(maxit = 100 ))
prob <- predict(model, lg.test, type = "response")

predicted.outcomes <- prob
print(predicted.outcomes)

    
lg.test$prediction = predicted.outcomes


    
lg.test %>% roc_plot(
         outcome = 'pstat',
         prediction = 'prediction',
         ci = TRUE, 
         plot_title= 'Single ROC curve w/CI ribbon')

lg.test %>%
  threshperf_plot(
                outcome = 'pstat',
                prediction = 'prediction')

lg.test %>%
  cal_plot(
         outcome = 'pstat', 
         prediction = 'prediction',
         show_loess = TRUE)

```

